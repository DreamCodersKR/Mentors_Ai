{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentee = {\n",
    "    \"name\": \"최지원\",\n",
    "    \"experience\": \"기초적인 Python 프로그래밍 경험이 있고, 머신러닝 입문 과정을 수강하였습니다. Kaggle에서 간단한 데이터 분석 프로젝트를 수행해보았습니다.\",\n",
    "    \"goals\": \"머신러닝 및 데이터 분석 역량을 키워, 향후 AI 연구자로 성장하고 싶습니다.\",\n",
    "    \"level\": \"초급\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "mentors = [\n",
    "    {\n",
    "        \"name\": \"김현우\",\n",
    "        \"mentoring_area\": [\"데이터 분석\", \"Python\", \"통계\"],\n",
    "        \"skills\": [\"Python\", \"Pandas\", \"Matplotlib\", \"Seaborn\", \"머신러닝\"],\n",
    "        \"desired_mentee_level\": \"초급\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"박지훈\",\n",
    "        \"mentoring_area\": [\"빅데이터\", \"데이터 엔지니어링\", \"SQL\"],\n",
    "        \"skills\": [\"SQL\", \"Spark\", \"Hadoop\", \"ETL\", \"데이터 파이프라인\"],\n",
    "        \"desired_mentee_level\": \"중급\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"이서연\",\n",
    "        \"mentoring_area\": [\"AI 모델링\", \"딥러닝\", \"컴퓨터 비전\"],\n",
    "        \"skills\": [\"TensorFlow\", \"Keras\", \"OpenCV\", \"PyTorch\"],\n",
    "        \"desired_mentee_level\": \"초급\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"정민수\",\n",
    "        \"mentoring_area\": [\"Java\", \"백엔드 개발\", \"API 설계\"],\n",
    "        \"skills\": [\"Java\", \"Spring Boot\", \"MySQL\", \"REST API\", \"Maven\"],\n",
    "        \"desired_mentee_level\": \"중급\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"최하영\",\n",
    "        \"mentoring_area\": [\"마케팅\", \"데이터 분석\", \"SNS 운영\"],\n",
    "        \"skills\": [\"Excel\", \"PowerPoint\", \"SEO\", \"SNS 광고\"],\n",
    "        \"desired_mentee_level\": \"초급\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"한재민\",\n",
    "        \"mentoring_area\": [\"데이터 시각화\", \"Python\", \"BI 도구\"],\n",
    "        \"skills\": [\"Tableau\", \"Power BI\", \"Python\", \"시각화 기법\"],\n",
    "        \"desired_mentee_level\": \"초급\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"이하늘\",\n",
    "        \"mentoring_area\": [\"법률 상담\", \"지적 재산권\"],\n",
    "        \"skills\": [\"지적재산권\", \"계약법\", \"민사소송법\"],\n",
    "        \"desired_mentee_level\": \"상급\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"류진영\",\n",
    "        \"mentoring_area\": [\"데이터 사이언스\", \"머신러닝\", \"AI\"],\n",
    "        \"skills\": [\"Scikit-learn\", \"Python\", \"R\", \"머신러닝 알고리즘\"],\n",
    "        \"desired_mentee_level\": \"초급\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"김나영\",\n",
    "        \"mentoring_area\": [\"프론트엔드 개발\", \"UI/UX 디자인\"],\n",
    "        \"skills\": [\"HTML\", \"CSS\", \"JavaScript\", \"React\", \"Figma\"],\n",
    "        \"desired_mentee_level\": \"중급\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"오승민\",\n",
    "        \"mentoring_area\": [\"모바일 앱 개발\", \"iOS 개발\"],\n",
    "        \"skills\": [\"Swift\", \"Objective-C\", \"Xcode\", \"UI 설계\"],\n",
    "        \"desired_mentee_level\": \"상급\"\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'머신 러닝 데이터 분석 역량 키우 향후 연구자 성장 ai'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentee_goals_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모바일 개발 개발 ios\n",
      "설계 swift objectivec xcode ui\n"
     ]
    }
   ],
   "source": [
    "print(mentor_area_processed)\n",
    "# print(mentor_area_embedding)\n",
    "print(mentor_skills_processed)\n",
    "# print(mentor_skills_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_kor = set([\n",
    "    \"이\", \"그\", \"저\", \"것\", \"등\", \"및\", \"의\", \"가\", \"을\", \"를\", \"은\", \"는\", \"에\", \"있\", \"하\", \n",
    "    \"되\", \"수\", \"보\", \"않\", \"없\", \"때\", \"년\", \"월\", \"일\", \"처럼\", \"하게\", \"합니다\", \"그리고\", \n",
    "    \"저는\", \"합니다\", \"있는\", \"있습니다\", \"같습니다\", \"대한\", \"통해\", \"더\", \"많이\", \"가장\", \n",
    "    \"이런\", \"저런\", \"그런\", \"안녕\", \"하세요\", \"있다\", \"하지만\", \"그러나\", \"그런데\", \"때문에\",\n",
    "    \"그래서\", \"또한\", \"하지만\", \"즉\", \"입니다\", \"더욱\", \"하여\", \"그리고\", \"하지만\", \"입니다\", \n",
    "    \"이므로\", \"대한\", \"위해\", \"중\", \"저희\", \"우리\", \"이후\", \"모든\", \"이전\", \"이외\", \"때문\", \n",
    "    \"이에\", \"관한\", \"해서\", \"그것\", \"매우\", \"상당히\", \"거의\", \"또는\", \"듯하다\", \"바로\", \"그렇지\",\n",
    "    \"이렇게\", \"저렇게\", \"알다\", \"많다\", \"적다\", \"모르다\", \"싶다\", \"기\", \"할\", \"로\", \"에서\", \n",
    "    \"명\", \"바\", \"며\", \"또\", \"만\", \"좀\", \"잘\", \"오\", \"가장\", \"에서\", \"와\", \"부터\", \"나\", \n",
    "    \"이랑\", \"까지\", \"하지\", \"하여\", \"그런\", \"이란\", \"따라\", \"이든\", \"마다\", \"처럼\", \n",
    "    \"하면서\", \"다면\", \"보다\", \"대로\", \"만큼\", \"누구\", \"한\", \"속\", \"겸\", \"너\", \"저\", \n",
    "    \"앞\", \"위\", \"끝\", \"뒤\", \"밑\", \"옆\", \"이전\", \"대로\", \"전\", \"후\", \"함께\",\n",
    "    \"능숙\", \"다양한\", \"성공\", \"완수\",\"현재\",\"현\",\"재\",\"도움\",\"경험\",\"제\",\"조금\",\"시\",\"투비\",\n",
    "    \"수준\",\"그러니까\", \"그래도\", \"그래서\", \"그러면\", \"그렇다면\", \"하지만\", \"다만\", \"물론\", \"왜냐하면\", \"사실\", \n",
    "    \"결국\", \"예를 들어\", \"예컨대\", \"예시로\", \"다시 말해\", \"즉\", \"이런 식으로\", \"이러한\", \"이것\", \"그것\", \n",
    "    \"이와 같은\", \"마찬가지로\", \"때로는\", \"보통\", \"자주\", \"특히\", \"일반적으로\", \"대부분\", \"일부\", \"모든\", \n",
    "    \"각종\", \"다양한\", \"여러\", \"무엇보다도\", \"동시에\", \"일단\", \"먼저\", \"또한\", \"더불어\", \"함께\", \"그리고\", \n",
    "    \"혹은\", \"아니면\", \"즉시\", \"그러나\", \"혹시\", \"언제든지\", \"얼마든지\", \"모든\", \"이러한 경우\", \"이럴 때\", \n",
    "    \"하지만\", \"물론\", \"따라서\", \"이러한 이유로\", \"그 결과\", \"이와 같이\", \"사실은\", \"실제로\", \"과연\", \"확실히\", \n",
    "    \"아마도\", \"대체로\", \"예를 들면\", \"가령\", \"먼저\", \"특히\", \"더군다나\", \"단지\", \"오히려\", \"일단\", \"일종의\", \n",
    "    \"약간\", \"상당히\", \"거의\", \"비교적\", \"적어도\", \"최소한\", \"최대한\", \"결국\", \"이처럼\", \"바로\", \"또\", \"등\", \n",
    "    \"등등\", \"등으로\", \"따위\", \"정도\", \"약\", \"그럼\", \"그랬더니\", \"게다가\", \"혹시\", \"가끔\", \"전혀\", \"매우\", \n",
    "    \"무척\", \"너무\", \"더욱\", \"더\", \"가장\", \"최선\", \"최고로\", \"아니\", \"예외적으로\", \"특히\", \"별로\", \"거의\", \n",
    "    \"오직\", \"단지\", \"뿐만 아니라\", \"그리고\", \"그러나\", \"그렇지만\", \"한편\", \"또한\", \"다시\", \"끝으로\", \"첫째\", \n",
    "    \"둘째\", \"셋째\", \"네\", \"어\", \"응\", \"맞아\", \"그렇지\", \"아마\", \"아마도\", \"혹시\", \"어쩌면\", \"다행히\", \"마침\", \n",
    "    \"우연히\", \"의외로\", \"뜻밖에\", \"실은\", \"사실\", \"실제로\", \"흔히\", \"보통\", \"주로\", \"대개\", \"일반적으로\", \n",
    "    \"대부분\", \"거의\", \"항상\", \"때때로\", \"종종\", \"가끔\", \"드물게\", \"간혹\", \"여기에\", \"게다가\", \"더불어\", \n",
    "    \"사실상\", \"일종의\", \"대략\", \"즉\", \"말하자면\", \"예를 들어\", \"예컨대\", \"어떤\", \"이와 같은\", \"그와 같은\", \n",
    "    \"이러한\", \"그런\", \"같은\", \"이런저런\", \"여기서\", \"여기까지\", \"이러한 점에서\", \"그 결과로\", \"이와 반대로\", \n",
    "    \"한편으로는\", \"앞서 말한 것처럼\",\"이러이러하다\", \"하구나\", \"하도다\", \"다시말하면\", \"다음으로\", \"에 있다\", \"에 달려 있다\", \n",
    "    \"우리\", \"우리들\", \"오히려\", \"하기는한데\", \"어떻게\", \"어떻해\", \"어찌됏어\", \"어때\", \"어째서\", \n",
    "    \"본대로\", \"자\", \"이\", \"이쪽\", \"여기\", \"이것\", \"이번\", \"이렇게말하자면\", \"이런\", \"이러한\", \n",
    "    \"이와 같은\", \"요만큼\", \"요만한 것\", \"얼마 안 되는 것\", \"이만큼\", \"이 정도의\", \"이렇게 많은 것\", \n",
    "    \"이와 같다\", \"이때\", \"이렇구나\", \"것과 같이\", \"끼익\", \"삐걱\", \"따위\", \"와 같은 사람들\", \n",
    "    \"부류의 사람들\", \"왜냐하면\", \"중의하나\", \"오직\", \"오로지\", \"에 한하다\", \"하기만 하면\", \n",
    "    \"도착하다\", \"까지 미치다\", \"도달하다\", \"정도에 이르다\", \"할 지경이다\", \"결과에 이르다\", \n",
    "    \"관해서는\", \"여러분\", \"하고 있다\", \"한 후\", \"혼자\", \"자기\", \"자기집\", \"자신\", \n",
    "    \"우에 종합한것과같이\", \"총적으로 보면\", \"총적으로 말하면\", \"총적으로\", \"대로 하다\", \"으로서\", \n",
    "    \"참\", \"그만이다\", \"할 따름이다\", \"쿵\", \"탕탕\", \"쾅쾅\", \"둥둥\", \"봐\", \"봐라\", \n",
    "    \"아이야\", \"아니\", \"와아\", \"응\", \"아이\", \"참나\", \"년\", \"월\", \"일\", \"령\", \n",
    "    \"영\", \"일\", \"이\", \"삼\", \"사\", \"오\", \"육\", \"륙\", \"칠\", \"팔\", \"구\", \n",
    "    \"이천육\", \"이천칠\", \"이천팔\", \"이천구\", \"하나\", \"둘\", \"셋\", \"넷\", \"다섯\", \"여섯\", \n",
    "    \"일곱\", \"여덟\", \"아홉\", \"령\", \"영\",\"그러니까\", \"그래도\", \"그래서\", \"그러면\", \"그렇다면\", \"하지만\", \"다만\", \"물론\", \n",
    "    \"왜냐하면\", \"사실\", \"결국\", \"예를 들어\", \"예컨대\", \"예시로\", \"다시 말해\", \"즉\", \n",
    "    \"이런 식으로\", \"이러한\", \"이것\", \"그것\", \"이와 같은\", \"마찬가지로\", \"때로는\", \n",
    "    \"보통\", \"자주\", \"특히\", \"일반적으로\", \"대부분\", \"일부\", \"모든\", \"각종\", \n",
    "    \"다양한\", \"여러\", \"무엇보다도\", \"동시에\", \"일단\", \"먼저\", \"또한\", \"더불어\", \n",
    "    \"함께\", \"그리고\", \"혹은\", \"아니면\", \"즉시\", \"그러나\", \"혹시\", \"언제든지\", \n",
    "    \"얼마든지\", \"모든\", \"이러한 경우\", \"이럴 때\", \"하지만\", \"물론\", \"따라서\", \n",
    "    \"이러한 이유로\", \"그 결과\", \"이와 같이\", \"사실은\", \"실제로\", \"과연\", \"확실히\", \n",
    "    \"아마도\", \"대체로\", \"예를 들면\", \"가령\", \"특히\", \"더군다나\", \"단지\", \"오히려\", \n",
    "    \"일단\", \"일종의\", \"약간\", \"상당히\", \"거의\", \"비교적\", \"적어도\", \"최소한\", \n",
    "    \"최대한\", \"결국\", \"이처럼\", \"바로\", \"또\", \"등\", \"등등\", \"등으로\", \"따위\", \n",
    "    \"정도\", \"약\", \"그럼\", \"그랬더니\", \"게다가\", \"혹시\", \"가끔\", \"전혀\", \"매우\", \n",
    "    \"무척\", \"너무\", \"더욱\", \"더\", \"가장\", \"최선\", \"최고로\", \"아니\", \"예외적으로\", \n",
    "    \"특히\", \"별로\", \"거의\", \"오직\", \"단지\", \"뿐만 아니라\", \"그리고\", \"그러나\", \n",
    "    \"그렇지만\", \"한편\", \"또한\", \"다시\", \"끝으로\", \"첫째\", \"둘째\", \"셋째\", \n",
    "    \"네\", \"어\", \"응\", \"맞아\", \"그렇지\", \"아마\", \"아마도\", \"혹시\", \"어쩌면\", \n",
    "    \"다행히\", \"마침\", \"우연히\", \"의외로\", \"뜻밖에\", \"실은\", \"사실\", \"실제로\", \n",
    "    \"흔히\", \"보통\", \"주로\", \"대개\", \"일반적으로\", \"대부분\", \"거의\", \"항상\", \n",
    "    \"때때로\", \"종종\", \"가끔\", \"드물게\", \"간혹\", \"여기에\", \"게다가\", \"더불어\", \n",
    "    \"사실상\", \"일종의\", \"대략\", \"즉\", \"말하자면\", \"예를 들어\", \"예컨대\", \n",
    "    \"어떤\", \"이와 같은\", \"그와 같은\", \"이러한\", \"그런\", \"같은\", \"이런저런\", \n",
    "    \"여기서\", \"여기까지\", \"이러한 점에서\", \"그 결과로\", \"이와 반대로\", \"한편으로는\", \n",
    "    \"앞서 말한 것처럼\",\"이\", \"있\", \"하\", \"것\", \"들\", \"그\", \"되\", \"수\", \"이\", \"보\", \"않\", \n",
    "    \"없\", \"나\", \"사람\", \"주\", \"아니\", \"등\", \"같\", \"우리\", \"때\", \"년\", \"가\", \"한\", \"지\", \n",
    "    \"대하\", \"오\", \"말\", \"일\", \"그렇\", \"위하\", \"때문\", \"그것\", \"두\", \"말하\", \"알\", \"그러나\", \n",
    "    \"받\", \"못하\", \"일\", \"그런\", \"또\", \"문제\", \"더\", \"사회\", \"많\", \"그리고\", \"좋\", \"크\", \"따르\", \"중\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\smhrd1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "멘토와의 적합도 점수:\n",
      "최하영: 0.8899\n",
      "오승민: 0.8887\n",
      "박지훈: 0.8717\n",
      "한재민: 0.8672\n",
      "김현우: 0.8531\n",
      "류진영: 0.8438\n",
      "이서연: 0.8224\n",
      "정민수: 0.8183\n",
      "이하늘: 0.8066\n",
      "김나영: 0.7923\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from konlpy.tag import Komoran\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from transformers import ElectraTokenizer, ElectraModel\n",
    "import torch\n",
    "\n",
    "# 한국어 불용어 목록 정의 (실제 불용어 목록을 여기에 넣으세요)\n",
    "korean_stopwords = stopwords_kor  # 실제 불용어 목록을 추가하세요\n",
    "\n",
    "# 영어 불용어 목록 정의\n",
    "english_stopwords = nltk_stopwords.words('english')\n",
    "\n",
    "# Komoran 형태소 분석기 인스턴스 생성\n",
    "komoran = Komoran()\n",
    "\n",
    "# KoELECTRA 모델 및 토크나이저 로드\n",
    "tokenizer = ElectraTokenizer.from_pretrained('monologg/koelectra-base-v3-discriminator')\n",
    "model = ElectraModel.from_pretrained('monologg/koelectra-base-v3-discriminator')\n",
    "# tokenizer = ElectraTokenizer.from_pretrained('monologg/kocharelectra-base-modu-ner-all')\n",
    "# model = ElectraModel.from_pretrained('monologg/kocharelectra-base-modu-ner-all')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 전처리\n",
    "    text = re.sub(r'[^ㄱ-ㅎ가-힣a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.lower()\n",
    "    tokens = komoran.pos(text)\n",
    "    selected_pos = ['NNG', 'NNP', 'VV', 'VA', 'XR']\n",
    "    korean_words = [word for word, pos in tokens if pos in selected_pos and word not in korean_stopwords]\n",
    "    english_words = re.findall(r'\\b[a-z]+\\b', text)\n",
    "    english_words = [word for word in english_words if word not in english_stopwords]\n",
    "    words = korean_words + english_words\n",
    "    return ' '.join(words)\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # [CLS] 토큰의 임베딩 사용\n",
    "    embedding = outputs.last_hidden_state[:, 0, :].detach().numpy()\n",
    "    return embedding.squeeze()\n",
    "\n",
    "\n",
    "# 적합도 계산 함수\n",
    "def calculate_fit(mentee, mentors):\n",
    "    fit_scores = []\n",
    "\n",
    "    # 멘티 정보 전처리 및 임베딩 생성\n",
    "    mentee_text = mentee[\"experience\"] + \" \" + mentee[\"goals\"]\n",
    "    mentee_processed = preprocess_text(mentee_text)\n",
    "    mentee_embedding = get_embedding(mentee_processed)\n",
    "\n",
    "    for mentor in mentors:\n",
    "        # 멘토 정보 전처리 및 임베딩 생성\n",
    "        mentor_text = ' '.join(mentor[\"mentoring_area\"] + mentor[\"skills\"])\n",
    "        mentor_processed = preprocess_text(mentor_text)\n",
    "        mentor_embedding = get_embedding(mentor_processed)\n",
    "\n",
    "        # 유사도 계산\n",
    "        similarity = cosine_similarity(\n",
    "            [mentee_embedding],\n",
    "            [mentor_embedding]\n",
    "        )[0][0]\n",
    "\n",
    "        # 레벨 일치 여부에 따른 가중치 적용\n",
    "        if mentee[\"level\"] == mentor[\"desired_mentee_level\"]:\n",
    "            level_weight = 1.0\n",
    "        else:\n",
    "            level_weight = 1.0  # 레벨이 맞지 않을 경우 가중치 감소\n",
    "\n",
    "        # 총합 점수 계산\n",
    "        total_score = similarity * level_weight\n",
    "        fit_scores.append((mentor[\"name\"], total_score))\n",
    "\n",
    "    return sorted(fit_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 멘토와의 적합도 계산 결과 출력\n",
    "fit_results = calculate_fit(mentee, mentors)\n",
    "print(\"멘토와의 적합도 점수:\")\n",
    "for mentor_name, score in fit_results:\n",
    "    print(f\"{mentor_name}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\smhrd1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "멘토와의 적합도 점수:\n",
      "김현우: 0.8985\n",
      "최하영: 0.8912\n",
      "이서연: 0.8869\n",
      "류진영: 0.8778\n",
      "정민수: 0.8705\n",
      "김나영: 0.8529\n",
      "한재민: 0.8449\n",
      "박지훈: 0.8327\n",
      "오승민: 0.7800\n",
      "이하늘: 0.6249\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from konlpy.tag import Komoran\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from transformers import ElectraTokenizer, ElectraModel\n",
    "import torch\n",
    "\n",
    "# 한국어 불용어 목록 정의 (실제 불용어 목록을 여기에 넣으세요)\n",
    "korean_stopwords = []  # 실제 불용어 목록을 추가하세요\n",
    "\n",
    "# 영어 불용어 목록 정의\n",
    "english_stopwords = nltk_stopwords.words('english')\n",
    "\n",
    "# Komoran 형태소 분석기 인스턴스 생성\n",
    "komoran = Komoran()\n",
    "\n",
    "# KoELECTRA 모델 및 토크나이저 로드\n",
    "tokenizer = ElectraTokenizer.from_pretrained('monologg/koelectra-base-v3-discriminator')\n",
    "model = ElectraModel.from_pretrained('monologg/koelectra-base-v3-discriminator')\n",
    "# tokenizer = ElectraTokenizer.from_pretrained('monologg/kocharelectra-base-modu-ner-all')\n",
    "# model = ElectraModel.from_pretrained('monologg/kocharelectra-base-modu-ner-all')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 전처리\n",
    "    text = re.sub(r'[^ㄱ-ㅎ가-힣a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.lower()\n",
    "    tokens = komoran.pos(text)\n",
    "    selected_pos = ['NNG', 'NNP', 'VV', 'VA', 'XR']\n",
    "    korean_words = [word for word, pos in tokens if pos in selected_pos and word not in korean_stopwords]\n",
    "    english_words = re.findall(r'\\b[a-z]+\\b', text)\n",
    "    english_words = [word for word in english_words if word not in english_stopwords]\n",
    "    words = korean_words + english_words\n",
    "    return ' '.join(words)\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # [CLS] 토큰의 임베딩 사용\n",
    "    embedding = outputs.last_hidden_state[:, 0, :].detach().numpy()\n",
    "    return embedding.squeeze()\n",
    "\n",
    "# 가중치 설정\n",
    "goals_area_weight = 0.3        # 가장 높은 가중치\n",
    "experience_area_weight = 0.6    # 중간 가중치\n",
    "goals_skills_weight = 0.1       # 중간보다 낮은 가중치\n",
    "\n",
    "# 적합도 계산 함수\n",
    "def calculate_fit(mentee, mentors):\n",
    "    fit_scores = []\n",
    "\n",
    "    # 멘티의 goals와 experience 전처리 및 임베딩 생성\n",
    "    mentee_goals_processed = preprocess_text(mentee[\"goals\"])\n",
    "    mentee_goals_embedding = get_embedding(mentee_goals_processed)\n",
    "\n",
    "    mentee_experience_processed = preprocess_text(mentee[\"experience\"])\n",
    "    mentee_experience_embedding = get_embedding(mentee_experience_processed)\n",
    "\n",
    "    for mentor in mentors:\n",
    "        # 멘토의 mentoring_area와 skills 전처리 및 임베딩 생성\n",
    "        mentor_area_processed = preprocess_text(' '.join(mentor[\"mentoring_area\"]))\n",
    "        mentor_area_embedding = get_embedding(mentor_area_processed)\n",
    "\n",
    "        mentor_skills_processed = preprocess_text(' '.join(mentor[\"skills\"]))\n",
    "        mentor_skills_embedding = get_embedding(mentor_skills_processed)\n",
    "\n",
    "        # 유사도 계산\n",
    "        # 1. 멘티의 goals와 멘토의 mentoring_area 간의 유사도 (가장 높은 가중치)\n",
    "        goals_area_similarity = cosine_similarity(\n",
    "            [mentee_goals_embedding],\n",
    "            [mentor_area_embedding]\n",
    "        )[0][0]\n",
    "\n",
    "        # 2. 멘티의 experience와 멘토의 mentoring_area 간의 유사도 (중간 가중치)\n",
    "        experience_area_similarity = cosine_similarity(\n",
    "            [mentee_experience_embedding],\n",
    "            [mentor_area_embedding]\n",
    "        )[0][0]\n",
    "\n",
    "        # 3. 멘티의 goals와 멘토의 skills 간의 유사도 (중간보다 낮은 가중치)\n",
    "        goals_skills_similarity = cosine_similarity(\n",
    "            [mentee_goals_embedding],\n",
    "            [mentor_skills_embedding]\n",
    "        )[0][0]\n",
    "\n",
    "        # 가중치 적용하여 총 유사도 계산\n",
    "        total_similarity = (\n",
    "            goals_area_similarity * goals_area_weight +\n",
    "            experience_area_similarity * experience_area_weight +\n",
    "            goals_skills_similarity * goals_skills_weight\n",
    "        )\n",
    "\n",
    "        # 레벨 일치 여부에 따른 작은 가중치 적용\n",
    "        if mentee[\"level\"] == mentor[\"desired_mentee_level\"]:\n",
    "            level_bonus = 0.01  # 작은 보너스\n",
    "        else:\n",
    "            level_bonus = 0.0\n",
    "\n",
    "        # 총합 점수 계산\n",
    "        total_score = total_similarity + level_bonus\n",
    "        fit_scores.append((mentor[\"name\"], total_score))\n",
    "\n",
    "    return sorted(fit_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 멘토와의 적합도 계산 결과 출력\n",
    "fit_results = calculate_fit(mentee, mentors)\n",
    "print(\"멘토와의 적합도 점수:\")\n",
    "for mentor_name, score in fit_results:\n",
    "    print(f\"{mentor_name}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\smhrd1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Some weights of CustomElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\smhrd1\\AppData\\Local\\Temp\\ipykernel_13264\\3275472011.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('../models/KoELECTRA_mentor_mentee.pth', map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "멘토와의 적합도 점수:\n",
      "최하영: 0.9328\n",
      "류진영: 0.9265\n",
      "이서연: 0.9148\n",
      "정민수: 0.9145\n",
      "김나영: 0.8969\n",
      "김현우: 0.8967\n",
      "한재민: 0.8837\n",
      "이하늘: 0.8528\n",
      "박지훈: 0.8284\n",
      "오승민: 0.6880\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from konlpy.tag import Komoran\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "from transformers import ElectraTokenizer, ElectraPreTrainedModel, ElectraModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 한국어 불용어 목록 정의 (실제 불용어 목록을 여기에 넣으세요)\n",
    "korean_stopwords = stopwords_kor  # 예시로 빈 리스트, 실제 불용어 목록을 추가하세요\n",
    "\n",
    "# 영어 불용어 목록 정의\n",
    "english_stopwords = nltk_stopwords.words('english')\n",
    "\n",
    "# Komoran 형태소 분석기 인스턴스 생성\n",
    "komoran = Komoran()\n",
    "\n",
    "# KoELECTRA 모델 및 토크나이저 로드\n",
    "tokenizer = ElectraTokenizer.from_pretrained('monologg/koelectra-base-v3-discriminator')\n",
    "\n",
    "# 맞춤형 모델 클래스 정의\n",
    "class CustomElectraForSequenceClassification(ElectraPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.electra = ElectraModel(config)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        labels=None,\n",
    "        output_hidden_states=True,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.electra(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "        pooled_output = sequence_output[:, 0, :]  # [CLS] 토큰의 임베딩\n",
    "\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return output\n",
    "\n",
    "        return {'logits': logits, 'hidden_states': outputs.hidden_states}\n",
    "\n",
    "# 모델 로드\n",
    "model = CustomElectraForSequenceClassification.from_pretrained('monologg/koelectra-base-v3-discriminator', num_labels=1)\n",
    "state_dict = torch.load('../models/KoELECTRA_mentor_mentee.pth', map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 전처리\n",
    "    text = re.sub(r'[^ㄱ-ㅎ가-힣a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.lower()\n",
    "    tokens = komoran.pos(text)\n",
    "    selected_pos = ['NNG', 'NNP', 'VV', 'VA', 'XR']\n",
    "    korean_words = [word for word, pos in tokens if pos in selected_pos and word not in korean_stopwords]\n",
    "    english_words = re.findall(r'\\b[a-z]+\\b', text)\n",
    "    english_words = [word for word in english_words if word not in english_stopwords]\n",
    "    words = korean_words + english_words\n",
    "    return ' '.join(words)\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            token_type_ids=inputs.get('token_type_ids', None),\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True\n",
    "        )\n",
    "    # [CLS] 토큰의 임베딩 추출\n",
    "    embedding = outputs['hidden_states'][-1][:, 0, :].detach().numpy()\n",
    "    return embedding.squeeze()\n",
    "\n",
    "# 가중치 설정\n",
    "goals_area_weight = 0.5         # 가장 높은 가중치\n",
    "experience_area_weight = 0.3    # 중간 가중치\n",
    "goals_skills_weight = 0.2       # 중간보다 낮은 가중치\n",
    "\n",
    "\n",
    "# 적합도 계산 함수\n",
    "def calculate_fit(mentee, mentors):\n",
    "    fit_scores = []\n",
    "\n",
    "    # 멘티의 goals와 experience 전처리 및 임베딩 생성\n",
    "    mentee_goals_processed = preprocess_text(mentee[\"goals\"])\n",
    "    mentee_goals_embedding = get_embedding(mentee_goals_processed)\n",
    "\n",
    "    mentee_experience_processed = preprocess_text(mentee[\"experience\"])\n",
    "    mentee_experience_embedding = get_embedding(mentee_experience_processed)\n",
    "\n",
    "    for mentor in mentors:\n",
    "        # 멘토의 mentoring_area와 skills 전처리 및 임베딩 생성\n",
    "        mentor_area_processed = preprocess_text(' '.join(mentor[\"mentoring_area\"]))\n",
    "        mentor_area_embedding = get_embedding(mentor_area_processed)\n",
    "\n",
    "        mentor_skills_processed = preprocess_text(' '.join(mentor[\"skills\"]))\n",
    "        mentor_skills_embedding = get_embedding(mentor_skills_processed)\n",
    "\n",
    "        # 유사도 계산\n",
    "        # 1. 멘티의 goals와 멘토의 mentoring_area 간의 유사도\n",
    "        goals_area_similarity = cosine_similarity(\n",
    "            [mentee_goals_embedding],\n",
    "            [mentor_area_embedding]\n",
    "        )[0][0]\n",
    "\n",
    "        # 2. 멘티의 experience와 멘토의 mentoring_area 간의 유사도\n",
    "        experience_area_similarity = cosine_similarity(\n",
    "            [mentee_experience_embedding],\n",
    "            [mentor_area_embedding]\n",
    "        )[0][0]\n",
    "\n",
    "        # 3. 멘티의 goals와 멘토의 skills 간의 유사도\n",
    "        goals_skills_similarity = cosine_similarity(\n",
    "            [mentee_goals_embedding],\n",
    "            [mentor_skills_embedding]\n",
    "        )[0][0]\n",
    "\n",
    "        # 가중치 적용하여 총 유사도 계산\n",
    "        total_similarity = (\n",
    "            goals_area_similarity * goals_area_weight +\n",
    "            experience_area_similarity * experience_area_weight +\n",
    "            goals_skills_similarity * goals_skills_weight\n",
    "        )\n",
    "\n",
    "        # 레벨 일치 여부에 따른 작은 가중치 적용\n",
    "        if mentee[\"level\"] == mentor[\"desired_mentee_level\"]:\n",
    "            level_bonus = 0.01  # 작은 보너스\n",
    "        else:\n",
    "            level_bonus = 0.0\n",
    "\n",
    "        # 총합 점수 계산\n",
    "        total_score = total_similarity + level_bonus\n",
    "        fit_scores.append((mentor[\"name\"], total_score))\n",
    "\n",
    "    return sorted(fit_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 멘토와의 적합도 계산 결과 출력\n",
    "fit_results = calculate_fit(mentee, mentors)\n",
    "print(\"멘토와의 적합도 점수:\")\n",
    "for mentor_name, score in fit_results:\n",
    "    print(f\"{mentor_name}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mentors_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
