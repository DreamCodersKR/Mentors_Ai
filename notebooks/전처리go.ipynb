{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_kor = set([\n",
    "    \"이\", \"그\", \"저\", \"것\", \"등\", \"및\", \"의\", \"가\", \"을\", \"를\", \"은\", \"는\", \"에\", \"있\", \"하\", \n",
    "    \"되\", \"수\", \"보\", \"않\", \"없\", \"때\", \"년\", \"월\", \"일\", \"처럼\", \"하게\", \"합니다\", \"그리고\", \n",
    "    \"저는\", \"합니다\", \"있는\", \"있습니다\", \"같습니다\", \"대한\", \"통해\", \"더\", \"많이\", \"가장\", \n",
    "    \"이런\", \"저런\", \"그런\", \"안녕\", \"하세요\", \"있다\", \"하지만\", \"그러나\", \"그런데\", \"때문에\",\n",
    "    \"그래서\", \"또한\", \"하지만\", \"즉\", \"입니다\", \"더욱\", \"하여\", \"그리고\", \"하지만\", \"입니다\", \n",
    "    \"이므로\", \"대한\", \"위해\", \"중\", \"저희\", \"우리\", \"이후\", \"모든\", \"이전\", \"이외\", \"때문\", \n",
    "    \"이에\", \"관한\", \"해서\", \"그것\", \"매우\", \"상당히\", \"거의\", \"또는\", \"듯하다\", \"바로\", \"그렇지\",\n",
    "    \"이렇게\", \"저렇게\", \"알다\", \"많다\", \"적다\", \"모르다\", \"싶다\", \"기\", \"할\", \"로\", \"에서\", \n",
    "    \"명\", \"바\", \"며\", \"또\", \"만\", \"좀\", \"잘\", \"오\", \"가장\", \"에서\", \"와\", \"부터\", \"나\", \n",
    "    \"이랑\", \"까지\", \"하지\", \"하여\", \"그런\", \"이란\", \"따라\", \"이든\", \"마다\", \"처럼\", \n",
    "    \"하면서\", \"다면\", \"보다\", \"대로\", \"만큼\", \"누구\", \"한\", \"속\", \"겸\", \"너\", \"저\", \n",
    "    \"앞\", \"위\", \"끝\", \"뒤\", \"밑\", \"옆\", \"이전\", \"대로\", \"전\", \"후\", \"함께\",\n",
    "    \"능숙\", \"다양한\", \"성공\", \"완수\",\"현재\",\"현\",\"재\",\"도움\",\"경험\",\"제\",\"조금\",\"시\",\"투비\",\n",
    "    \"수준\",\"그러니까\", \"그래도\", \"그래서\", \"그러면\", \"그렇다면\", \"하지만\", \"다만\", \"물론\", \"왜냐하면\", \"사실\", \n",
    "    \"결국\", \"예를 들어\", \"예컨대\", \"예시로\", \"다시 말해\", \"즉\", \"이런 식으로\", \"이러한\", \"이것\", \"그것\", \n",
    "    \"이와 같은\", \"마찬가지로\", \"때로는\", \"보통\", \"자주\", \"특히\", \"일반적으로\", \"대부분\", \"일부\", \"모든\", \n",
    "    \"각종\", \"다양한\", \"여러\", \"무엇보다도\", \"동시에\", \"일단\", \"먼저\", \"또한\", \"더불어\", \"함께\", \"그리고\", \n",
    "    \"혹은\", \"아니면\", \"즉시\", \"그러나\", \"혹시\", \"언제든지\", \"얼마든지\", \"모든\", \"이러한 경우\", \"이럴 때\", \n",
    "    \"하지만\", \"물론\", \"따라서\", \"이러한 이유로\", \"그 결과\", \"이와 같이\", \"사실은\", \"실제로\", \"과연\", \"확실히\", \n",
    "    \"아마도\", \"대체로\", \"예를 들면\", \"가령\", \"먼저\", \"특히\", \"더군다나\", \"단지\", \"오히려\", \"일단\", \"일종의\", \n",
    "    \"약간\", \"상당히\", \"거의\", \"비교적\", \"적어도\", \"최소한\", \"최대한\", \"결국\", \"이처럼\", \"바로\", \"또\", \"등\", \n",
    "    \"등등\", \"등으로\", \"따위\", \"정도\", \"약\", \"그럼\", \"그랬더니\", \"게다가\", \"혹시\", \"가끔\", \"전혀\", \"매우\", \n",
    "    \"무척\", \"너무\", \"더욱\", \"더\", \"가장\", \"최선\", \"최고로\", \"아니\", \"예외적으로\", \"특히\", \"별로\", \"거의\", \n",
    "    \"오직\", \"단지\", \"뿐만 아니라\", \"그리고\", \"그러나\", \"그렇지만\", \"한편\", \"또한\", \"다시\", \"끝으로\", \"첫째\", \n",
    "    \"둘째\", \"셋째\", \"네\", \"어\", \"응\", \"맞아\", \"그렇지\", \"아마\", \"아마도\", \"혹시\", \"어쩌면\", \"다행히\", \"마침\", \n",
    "    \"우연히\", \"의외로\", \"뜻밖에\", \"실은\", \"사실\", \"실제로\", \"흔히\", \"보통\", \"주로\", \"대개\", \"일반적으로\", \n",
    "    \"대부분\", \"거의\", \"항상\", \"때때로\", \"종종\", \"가끔\", \"드물게\", \"간혹\", \"여기에\", \"게다가\", \"더불어\", \n",
    "    \"사실상\", \"일종의\", \"대략\", \"즉\", \"말하자면\", \"예를 들어\", \"예컨대\", \"어떤\", \"이와 같은\", \"그와 같은\", \n",
    "    \"이러한\", \"그런\", \"같은\", \"이런저런\", \"여기서\", \"여기까지\", \"이러한 점에서\", \"그 결과로\", \"이와 반대로\", \n",
    "    \"한편으로는\", \"앞서 말한 것처럼\",\"이러이러하다\", \"하구나\", \"하도다\", \"다시말하면\", \"다음으로\", \"에 있다\", \"에 달려 있다\", \n",
    "    \"우리\", \"우리들\", \"오히려\", \"하기는한데\", \"어떻게\", \"어떻해\", \"어찌됏어\", \"어때\", \"어째서\", \n",
    "    \"본대로\", \"자\", \"이\", \"이쪽\", \"여기\", \"이것\", \"이번\", \"이렇게말하자면\", \"이런\", \"이러한\", \n",
    "    \"이와 같은\", \"요만큼\", \"요만한 것\", \"얼마 안 되는 것\", \"이만큼\", \"이 정도의\", \"이렇게 많은 것\", \n",
    "    \"이와 같다\", \"이때\", \"이렇구나\", \"것과 같이\", \"끼익\", \"삐걱\", \"따위\", \"와 같은 사람들\", \n",
    "    \"부류의 사람들\", \"왜냐하면\", \"중의하나\", \"오직\", \"오로지\", \"에 한하다\", \"하기만 하면\", \n",
    "    \"도착하다\", \"까지 미치다\", \"도달하다\", \"정도에 이르다\", \"할 지경이다\", \"결과에 이르다\", \n",
    "    \"관해서는\", \"여러분\", \"하고 있다\", \"한 후\", \"혼자\", \"자기\", \"자기집\", \"자신\", \n",
    "    \"우에 종합한것과같이\", \"총적으로 보면\", \"총적으로 말하면\", \"총적으로\", \"대로 하다\", \"으로서\", \n",
    "    \"참\", \"그만이다\", \"할 따름이다\", \"쿵\", \"탕탕\", \"쾅쾅\", \"둥둥\", \"봐\", \"봐라\", \n",
    "    \"아이야\", \"아니\", \"와아\", \"응\", \"아이\", \"참나\", \"년\", \"월\", \"일\", \"령\", \n",
    "    \"영\", \"일\", \"이\", \"삼\", \"사\", \"오\", \"육\", \"륙\", \"칠\", \"팔\", \"구\", \n",
    "    \"이천육\", \"이천칠\", \"이천팔\", \"이천구\", \"하나\", \"둘\", \"셋\", \"넷\", \"다섯\", \"여섯\", \n",
    "    \"일곱\", \"여덟\", \"아홉\", \"령\", \"영\",\"그러니까\", \"그래도\", \"그래서\", \"그러면\", \"그렇다면\", \"하지만\", \"다만\", \"물론\", \n",
    "    \"왜냐하면\", \"사실\", \"결국\", \"예를 들어\", \"예컨대\", \"예시로\", \"다시 말해\", \"즉\", \n",
    "    \"이런 식으로\", \"이러한\", \"이것\", \"그것\", \"이와 같은\", \"마찬가지로\", \"때로는\", \n",
    "    \"보통\", \"자주\", \"특히\", \"일반적으로\", \"대부분\", \"일부\", \"모든\", \"각종\", \n",
    "    \"다양한\", \"여러\", \"무엇보다도\", \"동시에\", \"일단\", \"먼저\", \"또한\", \"더불어\", \n",
    "    \"함께\", \"그리고\", \"혹은\", \"아니면\", \"즉시\", \"그러나\", \"혹시\", \"언제든지\", \n",
    "    \"얼마든지\", \"모든\", \"이러한 경우\", \"이럴 때\", \"하지만\", \"물론\", \"따라서\", \n",
    "    \"이러한 이유로\", \"그 결과\", \"이와 같이\", \"사실은\", \"실제로\", \"과연\", \"확실히\", \n",
    "    \"아마도\", \"대체로\", \"예를 들면\", \"가령\", \"특히\", \"더군다나\", \"단지\", \"오히려\", \n",
    "    \"일단\", \"일종의\", \"약간\", \"상당히\", \"거의\", \"비교적\", \"적어도\", \"최소한\", \n",
    "    \"최대한\", \"결국\", \"이처럼\", \"바로\", \"또\", \"등\", \"등등\", \"등으로\", \"따위\", \n",
    "    \"정도\", \"약\", \"그럼\", \"그랬더니\", \"게다가\", \"혹시\", \"가끔\", \"전혀\", \"매우\", \n",
    "    \"무척\", \"너무\", \"더욱\", \"더\", \"가장\", \"최선\", \"최고로\", \"아니\", \"예외적으로\", \n",
    "    \"특히\", \"별로\", \"거의\", \"오직\", \"단지\", \"뿐만 아니라\", \"그리고\", \"그러나\", \n",
    "    \"그렇지만\", \"한편\", \"또한\", \"다시\", \"끝으로\", \"첫째\", \"둘째\", \"셋째\", \n",
    "    \"네\", \"어\", \"응\", \"맞아\", \"그렇지\", \"아마\", \"아마도\", \"혹시\", \"어쩌면\", \n",
    "    \"다행히\", \"마침\", \"우연히\", \"의외로\", \"뜻밖에\", \"실은\", \"사실\", \"실제로\", \n",
    "    \"흔히\", \"보통\", \"주로\", \"대개\", \"일반적으로\", \"대부분\", \"거의\", \"항상\", \n",
    "    \"때때로\", \"종종\", \"가끔\", \"드물게\", \"간혹\", \"여기에\", \"게다가\", \"더불어\", \n",
    "    \"사실상\", \"일종의\", \"대략\", \"즉\", \"말하자면\", \"예를 들어\", \"예컨대\", \n",
    "    \"어떤\", \"이와 같은\", \"그와 같은\", \"이러한\", \"그런\", \"같은\", \"이런저런\", \n",
    "    \"여기서\", \"여기까지\", \"이러한 점에서\", \"그 결과로\", \"이와 반대로\", \"한편으로는\", \n",
    "    \"앞서 말한 것처럼\",\"이\", \"있\", \"하\", \"것\", \"들\", \"그\", \"되\", \"수\", \"이\", \"보\", \"않\", \n",
    "    \"없\", \"나\", \"사람\", \"주\", \"아니\", \"등\", \"같\", \"우리\", \"때\", \"년\", \"가\", \"한\", \"지\", \n",
    "    \"대하\", \"오\", \"말\", \"일\", \"그렇\", \"위하\", \"때문\", \"그것\", \"두\", \"말하\", \"알\", \"그러나\", \n",
    "    \"받\", \"못하\", \"일\", \"그런\", \"또\", \"문제\", \"더\", \"사회\", \"많\", \"그리고\", \"좋\", \"크\", \"따르\", \"중\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\smhrd1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요약된 텍스트:\n",
      "- 네트워크공학 박사\n",
      "- 네트워크 지능화 기술 연구개발.\n",
      "\n",
      "키워드:\n",
      "지능\n",
      "의미\n",
      "연구개발\n",
      "사이언티스트\n",
      "분석\n",
      "박사\n",
      "모델링\n",
      "데이터\n",
      "네트워크\n",
      "기술\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from konlpy.tag import Komoran\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from transformers import ElectraTokenizer, ElectraModel\n",
    "import torch\n",
    "\n",
    "# 한국어 불용어 목록 정의 (실제 불용어 목록을 여기에 넣으세요)\n",
    "korean_stopwords = stopwords_kor\n",
    "\n",
    "# 영어 불용어 목록 정의\n",
    "english_stopwords = nltk_stopwords.words('english')\n",
    "\n",
    "# Komoran 형태소 분석기 인스턴스 생성\n",
    "komoran = Komoran()\n",
    "# monologg/kocharelectra-base-modu-ner-all\n",
    "# KoCharElectraTokenizer\n",
    "# KoELECTRA 모델 및 토크나이저 로드\n",
    "tokenizer = ElectraTokenizer.from_pretrained('monologg/kocharelectra-base-modu-ner-all')\n",
    "model = ElectraModel.from_pretrained('monologg/kocharelectra-base-modu-ner-all')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 전처리\n",
    "    text = re.sub(r'[^ㄱ-ㅎ가-힣a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.lower()\n",
    "    tokens = komoran.pos(text)\n",
    "    selected_pos = ['NNG', 'NNP', 'VV', 'VA', 'XR']\n",
    "    korean_words = [word for word, pos in tokens if pos in selected_pos and word not in korean_stopwords]\n",
    "    english_words = re.findall(r'\\b[a-z]+\\b', text)\n",
    "    english_words = [word for word in english_words if word not in english_stopwords]\n",
    "    words = korean_words + english_words\n",
    "    return ' '.join(words)\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    embedding = outputs.last_hidden_state[:, 0, :].detach().numpy()\n",
    "    return embedding.squeeze()\n",
    "\n",
    "text = \"\"\"- 데이터 사이언티스트\n",
    "- 네트워크공학 박사\n",
    "- 데이터 기반 의미 분석 및 AI 모델링 기술 연구개발\n",
    "- 네트워크 지능화 기술 연구개발.\"\"\"\n",
    "\n",
    "# 문장 단위로 분할\n",
    "sentences = text.strip().split('\\n')\n",
    "\n",
    "# 전처리 적용\n",
    "processed_sentences = [preprocess_text(sentence) for sentence in sentences]\n",
    "\n",
    "# 문장 임베딩 생성\n",
    "sentence_embeddings = [get_embedding(sentence) for sentence in processed_sentences]\n",
    "\n",
    "# 유사도 행렬 생성\n",
    "similarity_matrix = cosine_similarity(sentence_embeddings, sentence_embeddings)\n",
    "\n",
    "# 그래프 생성\n",
    "graph = nx.from_numpy_array(similarity_matrix)\n",
    "\n",
    "# TextRank 계산\n",
    "scores = nx.pagerank(graph)\n",
    "\n",
    "# 중요도 높은 순으로 문장 정렬\n",
    "ranked_sentences = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
    "\n",
    "# 요약된 텍스트 출력\n",
    "print(\"요약된 텍스트:\")\n",
    "for i in range(2):  # 상위 2문장만 출력\n",
    "    print(ranked_sentences[i][1])\n",
    "\n",
    "# 키워드 추출\n",
    "# 모든 단어 추출\n",
    "all_words = set(' '.join(processed_sentences).split())\n",
    "\n",
    "# 단어 임베딩 생성\n",
    "word_embeddings = {}\n",
    "for word in all_words:\n",
    "    word_embeddings[word] = get_embedding(word)\n",
    "\n",
    "# 단어 리스트 생성\n",
    "words_list = list(all_words)\n",
    "\n",
    "# 임베딩 행렬 생성\n",
    "embeddings_matrix = np.array([word_embeddings[word] for word in words_list])\n",
    "\n",
    "# 유사도 행렬 계산\n",
    "word_similarity_matrix = cosine_similarity(embeddings_matrix, embeddings_matrix)\n",
    "\n",
    "# 그래프 생성\n",
    "word_graph = nx.from_numpy_array(word_similarity_matrix)\n",
    "\n",
    "# TextRank 계산\n",
    "word_scores = nx.pagerank(word_graph)\n",
    "\n",
    "# 중요도 높은 순으로 단어 정렬\n",
    "ranked_words = sorted(((word_scores[i], word) for i, word in enumerate(words_list)), reverse=True)\n",
    "\n",
    "# 단어만 추출하여 리스트로 저장\n",
    "only_word = [word for score, word in ranked_words]\n",
    "\n",
    "# 상위 키워드 출력\n",
    "print(\"\\n키워드:\")\n",
    "for word in only_word[:10]:  # 상위 10개 단어만 출력\n",
    "    print(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['지능',\n",
       " '의미',\n",
       " '연구개발',\n",
       " '사이언티스트',\n",
       " '분석',\n",
       " '박사',\n",
       " '모델링',\n",
       " '데이터',\n",
       " '네트워크',\n",
       " '기술',\n",
       " '기반',\n",
       " '공학',\n",
       " 'ai']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"- 데이터 사이언티스트\n",
    "- 네트워크공학 박사\n",
    "- 데이터 기반 의미 분석 및 AI 모델링 기술 연구개발\n",
    "- 네트워크 지능화 기술 연구개발.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 멘티 데이터\n",
    "mentee = {\n",
    "    \"name\": \"윤하은\",\n",
    "    \"interests\": [\n",
    "        \"데이터 분석\",\n",
    "        \"Python 프로그래밍\"\n",
    "    ],\n",
    "    \"level\": 1,\n",
    "    \"bio\": \"데이터 분석과 Python 프로그래밍에 관심이 많은 취업 준비생입니다. 실무 경험을 쌓고 싶습니다.\"\n",
    "}\n",
    "\n",
    "# 여러 명의 멘토 리스트 (10명)\n",
    "mentors = [\n",
    "    {\n",
    "        \"name\": \"김수영\",\n",
    "        \"expertise\": [\n",
    "            \"데이터 시각화\",\n",
    "            \"Python\",\n",
    "            \"AI\"\n",
    "        ],\n",
    "        \"level\": 3,\n",
    "        \"bio\": \"데이터 시각화 및 AI 분야의 전문가입니다. Python을 통한 AI 모델 개발에 경험이 많습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"박민수\",\n",
    "        \"expertise\": [\n",
    "            \"프론트엔드 개발\",\n",
    "            \"React\",\n",
    "            \"JavaScript\"\n",
    "        ],\n",
    "        \"level\": 2,\n",
    "        \"bio\": \"프론트엔드 개발과 React에 대한 깊은 이해를 바탕으로 웹 개발 프로젝트를 성공적으로 이끌었습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"이하연\",\n",
    "        \"expertise\": [\n",
    "            \"데이터베이스\",\n",
    "            \"SQL\",\n",
    "            \"데이터 엔지니어링\"\n",
    "        ],\n",
    "        \"level\": 3,\n",
    "        \"bio\": \"SQL 및 데이터베이스 설계에 대한 풍부한 경험이 있으며, 데이터 엔지니어링 프로젝트를 다수 진행했습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"정윤호\",\n",
    "        \"expertise\": [\n",
    "            \"백엔드 개발\",\n",
    "            \"Node.js\",\n",
    "            \"AWS\"\n",
    "        ],\n",
    "        \"level\": 3,\n",
    "        \"bio\": \"백엔드 개발과 클라우드 서비스(AWS)에 대한 전문성을 보유하고 있으며, 서버 운영과 관련된 다양한 경험이 있습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"한지원\",\n",
    "        \"expertise\": [\n",
    "            \"기계 학습\",\n",
    "            \"TensorFlow\",\n",
    "            \"Keras\"\n",
    "        ],\n",
    "        \"level\": 2,\n",
    "        \"bio\": \"기계 학습 모델 개발과 관련된 프로젝트 경험이 풍부하며, TensorFlow와 Keras를 다루는 데 능숙합니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"서지호\",\n",
    "        \"expertise\": [\n",
    "            \"비즈니스 분석\",\n",
    "            \"프로젝트 관리\",\n",
    "            \"엑셀\"\n",
    "        ],\n",
    "        \"level\": 2,\n",
    "        \"bio\": \"엑셀을 활용한 비즈니스 분석과 프로젝트 관리 경험이 있으며, 기업의 생산성 향상을 위한 컨설팅을 제공하고 있습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"김나윤\",\n",
    "        \"expertise\": [\n",
    "            \"PPT 디자인\",\n",
    "            \"프레젠테이션\",\n",
    "            \"마케팅 전략\"\n",
    "        ],\n",
    "        \"level\": 3,\n",
    "        \"bio\": \"프레젠테이션과 PPT 디자인에 대한 경험이 풍부하며, 마케팅 전략을 효과적으로 전달하는 방법을 지도합니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"장민준\",\n",
    "        \"expertise\": [\n",
    "            \"AI 연구\",\n",
    "            \"자연어 처리\",\n",
    "            \"딥러닝\"\n",
    "        ],\n",
    "        \"level\": 3,\n",
    "        \"bio\": \"AI 연구와 자연어 처리 분야에서 다수의 프로젝트를 진행했으며, 딥러닝 모델 개발에 전문성을 가지고 있습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"최혜진\",\n",
    "        \"expertise\": [\n",
    "            \"UX/UI 디자인\",\n",
    "            \"사용자 경험\",\n",
    "            \"그래픽 디자인\"\n",
    "        ],\n",
    "        \"level\": 3,\n",
    "        \"bio\": \"UX/UI 디자인에 대한 깊은 이해와 다양한 사용자 경험 프로젝트를 진행했습니다. 그래픽 디자인에도 능숙합니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"이상혁\",\n",
    "        \"expertise\": [\n",
    "            \"모바일 앱 개발\",\n",
    "            \"Android\",\n",
    "            \"iOS\"\n",
    "        ],\n",
    "        \"level\": 2,\n",
    "        \"bio\": \"모바일 앱 개발(Android, iOS)에서의 경험이 많으며, 다양한 모바일 프로젝트를 성공적으로 완수했습니다.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멘티와 가장 매칭 확률이 높은 멘토 찾기\n",
    "best_mentor, best_prob = find_best_match(mentee, mentors)\n",
    "print(f\"가장 매칭률이 높은 멘토: {best_mentor['name']} (매칭 확률: {best_prob:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mentors_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
