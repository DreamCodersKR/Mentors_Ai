{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1729522306161,
     "user": {
      "displayName": "김영효",
      "userId": "02315814338804143440"
     },
     "user_tz": -540
    },
    "id": "UC42vZIPbE5V"
   },
   "outputs": [],
   "source": [
    "# !pip install boto3==1.15.18\n",
    "# !pip install gluonnlp==0.10.0\n",
    "# !pip install onnxruntime==1.8.0\n",
    "# !pip install sentencepiece==0.1.96\n",
    "# !pip install torch==1.10.1+cu102 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# !pip install transformers==4.8.1\n",
    "# !pip install ipywidgets\n",
    "# !pip install pandas\n",
    "# !pip install scikit-learn\n",
    "# !pip install torch\n",
    "# !pip install transformers\n",
    "# #인스톨이 안될경우 관리자 권한으로 vscode 실행바람\n",
    "\n",
    "\n",
    "# !pip install --upgrade transformers\n",
    "# #transformers 라이브러리 업그레이드\n",
    "\n",
    "# !pip install kobert-transformers\n",
    "# #kobert transformers 라이브러리 인스톨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1729522309067,
     "user": {
      "displayName": "김영효",
      "userId": "02315814338804143440"
     },
     "user_tz": -540
    },
    "id": "T1eDdxjicqyU"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../data/mentor_mentee_data.json', 'r', encoding='utf-8') as f:\n",
    "    data_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1729522309067,
     "user": {
      "displayName": "김영효",
      "userId": "02315814338804143440"
     },
     "user_tz": -540
    },
    "id": "XkFi3HWbcuUj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "texts = []  # 멘토와 멘티 소개를 결합한 텍스트 데이터를 저장할 리스트\n",
    "labels = []  # 멘토-멘티의 매칭 여부(라벨)를 저장할 리스트\n",
    "\n",
    "# 주어진 데이터 리스트(data_list)에서 멘토와 멘티의 정보를 추출\n",
    "for pair in data_list:\n",
    "    mentor_bio = pair['mentor']['bio']  # 멘토의 소개 정보\n",
    "    mentee_bio = pair['mentee']['bio']  # 멘티의 소개 정보\n",
    "    match = pair['match']  # 멘토-멘티의 매칭 여부 (라벨 값, 예: 1 또는 0)\n",
    "\n",
    "    # 멘토와 멘티의 소개를 결합하여 하나의 텍스트로 생성\n",
    "    text = f\"멘토 소개: {mentor_bio} 멘티 소개: {mentee_bio}\"\n",
    "    \n",
    "    # 텍스트 데이터를 리스트에 추가\n",
    "    texts.append(text)\n",
    "    \n",
    "    # 매칭 여부를 라벨 리스트에 추가\n",
    "    labels.append(match)\n",
    "\n",
    "# texts와 labels 리스트를 이용해 데이터프레임 생성\n",
    "df = pd.DataFrame({'text': texts, 'label': labels})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1729522309067,
     "user": {
      "displayName": "김영효",
      "userId": "02315814338804143440"
     },
     "user_tz": -540
    },
    "id": "o0DvhyHZcuqm"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['text'], df['label'], test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 706,
     "status": "ok",
     "timestamp": 1729522309771,
     "user": {
      "displayName": "김영효",
      "userId": "02315814338804143440"
     },
     "user_tz": -540
    },
    "id": "akQCWjVScu7S"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\smhrd1\\Desktop\\Mentors\\ai\\mentors_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import ElectraTokenizer, ElectraModel\n",
    "\n",
    "# KoELECTRA 모델과 토크나이저 로드\n",
    "tokenizer = ElectraTokenizer.from_pretrained('monologg/koelectra-base-v3-discriminator')\n",
    "model = ElectraModel.from_pretrained('monologg/koelectra-base-v3-discriminator')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1729522309771,
     "user": {
      "displayName": "김영효",
      "userId": "02315814338804143440"
     },
     "user_tz": -540
    },
    "id": "FlV3c0R0cvDZ"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class MentorMenteeDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        \"\"\"\n",
    "        MentorMenteeDataset 클래스 초기화\n",
    "        :param texts: 입력 텍스트 리스트 (멘토-멘티 소개)\n",
    "        :param labels: 각 텍스트에 대한 라벨 리스트 (매칭 여부)\n",
    "        :param tokenizer: 텍스트를 토큰화할 때 사용할 토크나이저 (예: KoBERT, KoELECTRA 등)\n",
    "        :param max_len: 최대 토큰 길이 (문장을 토큰화할 때 자를 길이)\n",
    "        \"\"\"\n",
    "        self.texts = texts.tolist()  # 텍스트 데이터를 리스트로 변환\n",
    "        self.labels = labels.tolist()  # 라벨 데이터를 리스트로 변환\n",
    "        self.tokenizer = tokenizer  # 토크나이저 객체 (BERT 기반)\n",
    "        self.max_len = max_len  # 최대 토큰 길이\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        데이터셋의 총 샘플 수를 반환\n",
    "        :return: 총 샘플 수 (texts 리스트의 길이)\n",
    "        \"\"\"\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        주어진 인덱스에 해당하는 샘플을 반환\n",
    "        :param idx: 데이터셋에서 가져올 샘플의 인덱스\n",
    "        :return: 토큰화된 입력 데이터와 라벨 (딕셔너리 형태)\n",
    "        \"\"\"\n",
    "        text = str(self.texts[idx])  # 인덱스에 해당하는 텍스트를 문자열로 변환\n",
    "        label = self.labels[idx]  # 인덱스에 해당하는 라벨을 가져옴\n",
    "\n",
    "        # 텍스트를 토큰화하고, 필요한 입력 형식으로 변환\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,  # [CLS], [SEP] 같은 특별 토큰 추가\n",
    "            max_length=self.max_len,  # 최대 길이를 지정하여 텍스트 자름\n",
    "            truncation=True,  # max_len을 초과하는 텍스트는 잘라냄\n",
    "            padding='max_length',  # max_len에 맞춰 패딩 추가\n",
    "            return_tensors='pt'  # PyTorch 텐서 형식으로 변환\n",
    "        )\n",
    "\n",
    "        # 토큰화된 결과를 딕셔너리 형태로 반환\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),  # 입력 토큰 ID (1차원 텐서로 변환)\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),  # 패딩 여부를 나타내는 마스크 (1차원 텐서)\n",
    "            'labels': torch.tensor(label, dtype=torch.float)  # 라벨 값을 PyTorch 텐서로 변환 (float 형식)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1729522309771,
     "user": {
      "displayName": "김영효",
      "userId": "02315814338804143440"
     },
     "user_tz": -540
    },
    "id": "Ynz_TfaYcvLt"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 128  # 각 입력 문장의 최대 토큰 길이 설정 (128 토큰으로 자르거나 패딩)\n",
    "BATCH_SIZE = 16  # 한 번에 처리할 데이터 샘플 수 (배치 크기)\n",
    "\n",
    "# 학습용 데이터셋을 생성\n",
    "# - train_texts: 학습용 텍스트 데이터 리스트\n",
    "# - train_labels: 학습용 라벨 리스트\n",
    "# - tokenizer: 텍스트를 토큰화하는 데 사용할 BERT 기반 토크나이저\n",
    "# - MAX_LEN: 각 문장의 최대 토큰 길이 (128)\n",
    "train_dataset = MentorMenteeDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "\n",
    "# 검증용 데이터셋을 생성\n",
    "# - val_texts: 검증용 텍스트 데이터 리스트\n",
    "# - val_labels: 검증용 라벨 리스트\n",
    "# - tokenizer: 검증용 데이터에도 같은 토크나이저와 설정을 사용\n",
    "# - MAX_LEN: 검증 데이터에도 동일하게 128 토큰으로 자르거나 패딩\n",
    "val_dataset = MentorMenteeDataset(val_texts, val_labels, tokenizer, MAX_LEN)\n",
    "\n",
    "# 학습용 DataLoader를 생성\n",
    "# - train_dataset: 학습용 MentorMenteeDataset 객체\n",
    "# - batch_size: BATCH_SIZE (한 번에 처리할 데이터 수)\n",
    "# - shuffle=True: 학습 시 데이터 순서를 섞어서 모델에 전달 (더 나은 일반화 성능)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# 검증용 DataLoader를 생성\n",
    "# - val_dataset: 검증용 MentorMenteeDataset 객체\n",
    "# - batch_size: BATCH_SIZE (검증 시에도 동일한 배치 크기로 처리)\n",
    "# - shuffle=False: 검증 데이터는 섞지 않음 (일관된 평가를 위해 순서를 유지)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1729522309772,
     "user": {
      "displayName": "김영효",
      "userId": "02315814338804143440"
     },
     "user_tz": -540
    },
    "id": "W95zEhEgcvTm"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class KoELECTRAClassifier(nn.Module):\n",
    "    def __init__(self, electra):\n",
    "        \"\"\"\n",
    "        KoELECTRAClassifier 클래스 초기화\n",
    "        :param electra: 사전 학습된 ELECTRA 모델 (KoELECTRA)\n",
    "        \"\"\"\n",
    "        super(KoELECTRAClassifier, self).__init__()\n",
    "        self.electra = electra  # ELECTRA 모델을 할당\n",
    "        self.dropout = nn.Dropout(0.3)  # 과적합 방지를 위한 드롭아웃 레이어 (30% 드롭아웃)\n",
    "        self.classifier = nn.Linear(electra.config.hidden_size, 1)  # ELECTRA 출력(hidden_size)을 1차원으로 변환하는 선형 레이어\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        순전파 계산\n",
    "        :param input_ids: 입력 토큰 ID들\n",
    "        :param attention_mask: 패딩된 부분을 무시하기 위한 어텐션 마스크\n",
    "        :return: 최종 출력 로짓 (분류 점수)\n",
    "        \"\"\"\n",
    "        # ELECTRA 모델의 순전파 진행 (입력값을 처리하여 마지막 히든 스테이트 반환)\n",
    "        outputs = self.electra(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        # [CLS] 토큰에 해당하는 첫 번째 토큰의 히든 스테이트를 사용\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]\n",
    "        \n",
    "        # 드롭아웃을 적용하여 과적합 방지\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        \n",
    "        # 선형 레이어를 통해 최종 분류 값 계산 (로짓 출력)\n",
    "        logits = self.classifier(dropout_output)\n",
    "        \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1729522309772,
     "user": {
      "displayName": "김영효",
      "userId": "02315814338804143440"
     },
     "user_tz": -540
    },
    "id": "5h05oDa_c1x8",
    "outputId": "7e87e0c6-1475-4ddc-c920-c0627c675284"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # True이면 GPU 사용 가능\n",
    "print(torch.cuda.device_count())  # 사용 가능한 GPU 개수 출력\n",
    "print(torch.cuda.get_device_name(0))  # 첫 번째 GPU 이름 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1729522309772,
     "user": {
      "displayName": "김영효",
      "userId": "02315814338804143440"
     },
     "user_tz": -540
    },
    "id": "HqFRSRB2c16w"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# GPU가 사용 가능하면 CUDA 장치를, 그렇지 않으면 CPU를 사용\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# KoELECTRAClassifier 모델을 생성하고, 지정된 장치(GPU 또는 CPU)로 이동\n",
    "model = KoELECTRAClassifier(model)  # KoELECTRA 기반 분류 모델\n",
    "model = model.to(device)  # 모델을 선택된 장치(GPU/CPU)로 이동\n",
    "\n",
    "# 이진 분류 문제에 사용되는 손실 함수 설정\n",
    "# BCEWithLogitsLoss는 출력 로짓(logits)을 입력으로 받아 이진 분류에서 손실을 계산\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)  # 손실 함수도 GPU로 이동\n",
    "\n",
    "# AdamW 옵티마이저 설정\n",
    "# 학습률(lr)은 2e-5로 설정되며, 모델의 파라미터들이 옵티마이저에 전달됨\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1729522309772,
     "user": {
      "displayName": "김영효",
      "userId": "02315814338804143440"
     },
     "user_tz": -540
    },
    "id": "7d9g1b6Cc2CG"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, loss_fn, optimizer, device):\n",
    "    \"\"\"\n",
    "    한 에폭 동안 모델을 학습하는 함수\n",
    "    :param model: 학습할 모델\n",
    "    :param data_loader: 학습 데이터 로더 (배치 단위로 데이터를 공급)\n",
    "    :param loss_fn: 손실 함수 (BCEWithLogitsLoss)\n",
    "    :param optimizer: 옵티마이저 (AdamW)\n",
    "    :param device: 학습을 실행할 장치 (GPU 또는 CPU)\n",
    "    :return: 배치당 평균 학습 손실 값\n",
    "    \"\"\"\n",
    "    model.train()  # 모델을 학습 모드로 설정\n",
    "    total_loss = 0  # 총 손실 값을 저장할 변수 초기화\n",
    "\n",
    "    # 데이터 로더를 통해 배치 단위로 학습 데이터 처리\n",
    "    for data in data_loader:\n",
    "        # 입력 데이터와 라벨을 장치(GPU/CPU)로 이동\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "        labels = data['labels'].to(device).unsqueeze(1)  # 라벨 차원을 모델 출력과 맞추기 위해 unsqueeze\n",
    "\n",
    "        # 모델 순전파 계산 (입력 데이터를 모델에 전달하여 예측 값 얻기)\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        \n",
    "        # 예측 값과 실제 라벨 간의 손실 계산\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        total_loss += loss.item()  # 손실 값을 누적\n",
    "        \n",
    "        # 역전파를 위한 그래디언트 초기화\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 역전파로 그래디언트 계산\n",
    "        loss.backward()\n",
    "        \n",
    "        # 옵티마이저로 모델 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "    # 배치당 평균 손실 반환\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device):\n",
    "    \"\"\"\n",
    "    모델을 평가하는 함수 (검증 데이터에 대한 손실 계산)\n",
    "    :param model: 평가할 모델\n",
    "    :param data_loader: 검증 데이터 로더 (배치 단위로 데이터를 공급)\n",
    "    :param loss_fn: 손실 함수 (BCEWithLogitsLoss)\n",
    "    :param device: 평가를 실행할 장치 (GPU 또는 CPU)\n",
    "    :return: 배치당 평균 검증 손실 값\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    total_loss = 0  # 총 손실 값을 저장할 변수 초기화\n",
    "\n",
    "    # 평가 시 그래디언트를 계산하지 않도록 설정 (메모리 절약)\n",
    "    with torch.no_grad():\n",
    "        # 데이터 로더를 통해 배치 단위로 검증 데이터 처리\n",
    "        for data in data_loader:\n",
    "            # 입력 데이터와 라벨을 장치(GPU/CPU)로 이동\n",
    "            input_ids = data['input_ids'].to(device)\n",
    "            attention_mask = data['attention_mask'].to(device)\n",
    "            labels = data['labels'].to(device).unsqueeze(1)  # 라벨 차원을 맞추기 위해 unsqueeze\n",
    "\n",
    "            # 모델 순전파 계산 (입력 데이터를 모델에 전달하여 예측 값 얻기)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            \n",
    "            # 예측 값과 실제 라벨 간의 손실 계산\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            total_loss += loss.item()  # 손실 값을 누적\n",
    "\n",
    "    # 배치당 평균 손실 반환\n",
    "    return total_loss / len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 274385,
     "status": "ok",
     "timestamp": 1729522584151,
     "user": {
      "displayName": "김영효",
      "userId": "02315814338804143440"
     },
     "user_tz": -540
    },
    "id": "iQS6mNMpc2Jc",
    "outputId": "e8196ee0-4b87-4997-feca-25b96148a16d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Train Loss: 0.2869 | Val Loss: 0.1164\n",
      "Epoch 2/3\n",
      "Train Loss: 0.0585 | Val Loss: 0.0120\n",
      "Epoch 3/3\n",
      "Train Loss: 0.0210 | Val Loss: 0.0146\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3  # 학습할 총 에폭 수 (총 3번의 에폭 동안 학습 및 검증 반복)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # 사용 가능한 장치 설정 (GPU 사용 가능 시 CUDA, 그렇지 않으면 CPU)\n",
    "\n",
    "# 에폭 수만큼 학습을 반복\n",
    "for epoch in range(EPOCHS):\n",
    "    # 현재 진행 중인 에폭 번호 출력 (에폭은 1부터 시작)\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}')\n",
    "    \n",
    "    # 한 에폭 동안 학습 데이터로 모델을 학습\n",
    "    train_loss = train_epoch(model, train_loader, loss_fn, optimizer, device)\n",
    "    \n",
    "    # 한 에폭 동안 검증 데이터로 모델을 평가\n",
    "    val_loss = eval_model(model, val_loader, loss_fn, device)\n",
    "    \n",
    "    # 학습 손실과 검증 손실을 출력\n",
    "    print(f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3342,
     "status": "ok",
     "timestamp": 1729522587490,
     "user": {
      "displayName": "김영효",
      "userId": "02315814338804143440"
     },
     "user_tz": -540
    },
    "id": "Tgls47Ybc2Q5",
    "outputId": "35287fde-07ee-433d-9e8d-ada8bfff98b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9956\n",
      "Precision: 0.9608\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.9800\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가라인\n",
    "def get_predictions(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    real_values = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            input_ids = data['input_ids'].to(device)\n",
    "            attention_mask = data['attention_mask'].to(device)\n",
    "            labels = data['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            preds = torch.sigmoid(outputs)\n",
    "            preds = preds.cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            real_values.extend(labels)\n",
    "\n",
    "    return predictions, real_values\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "preds, labels = get_predictions(model, val_loader, device)\n",
    "preds = [1 if p >= 0.5 else 0 for p in preds]\n",
    "\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "precision = precision_score(labels, preds)\n",
    "recall = recall_score(labels, preds)\n",
    "f1 = f1_score(labels, preds)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 3461,
     "status": "ok",
     "timestamp": 1729524595847,
     "user": {
      "displayName": "김영효",
      "userId": "02315814338804143440"
     },
     "user_tz": -540
    },
    "id": "pIdYzRjGmndN"
   },
   "outputs": [],
   "source": [
    "#모델저장\n",
    "torch.save(model.state_dict(), 'KoELECTRA_mentor_mentee.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1039,
     "status": "ok",
     "timestamp": 1729524596884,
     "user": {
      "displayName": "김영효",
      "userId": "02315814338804143440"
     },
     "user_tz": -540
    },
    "id": "nz5vO2XUc2YU",
    "outputId": "a271a9d5-27ef-4972-dd0b-348ba7de4112"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-52-8028b0281d6f>:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('KoELECTRA_mentor_mentee.pth', map_location=device))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import ElectraTokenizer, ElectraModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bert_model = ElectraModel.from_pretrained('monologg/koelectra-base-v3-discriminator')\n",
    "model = KoELECTRAClassifier(bert_model)\n",
    "model.load_state_dict(torch.load('KoELECTRA_mentor_mentee.pth', map_location=device))\n",
    "model = model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1729524596884,
     "user": {
      "displayName": "김영효",
      "userId": "02315814338804143440"
     },
     "user_tz": -540
    },
    "id": "1x2vNM9vc2fY",
    "outputId": "17e5772b-dcd2-4988-b49b-f8bba1e328ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "매칭 확률: 0.0021\n"
     ]
    }
   ],
   "source": [
    "#멘토 멘티 바이오 가져와서 매칭\n",
    "def predict_match(mentor_bio, mentee_bio):\n",
    "    text = f\"멘토 소개: {mentor_bio} 멘티 소개: {mentee_bio}\"\n",
    "\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LEN,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask)\n",
    "        prob = torch.sigmoid(output)\n",
    "        return prob.item()\n",
    "\n",
    "# 예시 사용\n",
    "mentor_bio = \"고급 단계의 엑셀 전문가입니다. 직장 생활의 노하우를 전수해드리겠습니다.\"\n",
    "mentee_bio = \"엑셀 활용법에 관심 있는 중급 멘티입니다. 많은 것을 배우고 싶습니다.\"\n",
    "\n",
    "match_prob = predict_match(mentor_bio, mentee_bio)\n",
    "print(f'매칭 확률: {match_prob:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 409,
     "status": "ok",
     "timestamp": 1729527033076,
     "user": {
      "displayName": "김영효",
      "userId": "02315814338804143440"
     },
     "user_tz": -540
    },
    "id": "MVf02KQZp68X",
    "outputId": "af859fb6-a5fe-4b4d-d466-c10bf902e0ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "멘토 김수영의 매칭 확률: 0.1479\n",
      "멘토 박민수의 매칭 확률: 0.4234\n",
      "멘토 이하연의 매칭 확률: 0.1517\n",
      "멘토 정윤호의 매칭 확률: 0.1789\n",
      "멘토 한지원의 매칭 확률: 0.1046\n",
      "멘토 서지호의 매칭 확률: 0.2796\n",
      "멘토 김나윤의 매칭 확률: 0.0762\n",
      "멘토 장민준의 매칭 확률: 0.0684\n",
      "멘토 최혜진의 매칭 확률: 0.2572\n",
      "멘토 이상혁의 매칭 확률: 0.4830\n",
      "가장 매칭률이 높은 멘토: 이상혁 (매칭 확률: 0.4830)\n"
     ]
    }
   ],
   "source": [
    "# 각 구성요소 매치시켜서 측정하는 함수\n",
    "def predict_match_from_data(pair):\n",
    "    mentor_expertise = \", \".join(pair['mentor']['expertise'])\n",
    "    mentee_interests = \", \".join(pair['mentee']['interests'])\n",
    "    mentor_level = pair['mentor']['level']\n",
    "    mentee_level = pair['mentee']['level']\n",
    "    mentor_bio = pair['mentor']['bio']\n",
    "    mentee_bio = pair['mentee']['bio']\n",
    "\n",
    "    # 학습 시 사용한 형식대로 입력 텍스트를 구성합니다.\n",
    "    text = (\n",
    "        f\"멘토 전문 분야: {mentor_expertise}, 멘토 레벨: {mentor_level}, \"\n",
    "        f\"멘토 소개: {mentor_bio}, 멘티 관심사: {mentee_interests}, \"\n",
    "        f\"멘티 레벨: {mentee_level}, 멘티 소개: {mentee_bio}\"\n",
    "    )\n",
    "\n",
    "    # 토크나이징 및 인코딩\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    # 모델 예측\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask)\n",
    "        prob = torch.sigmoid(output)\n",
    "        return prob.item()\n",
    "\n",
    "def find_best_match(mentee, mentors):\n",
    "    best_match_prob = -1\n",
    "    best_mentor = None\n",
    "\n",
    "    # 각 멘토와 멘티의 매칭 확률을 계산하고 가장 높은 매칭 확률을 가진 멘토 선택\n",
    "    for mentor in mentors:\n",
    "        pair = {\n",
    "            \"mentor\": mentor,\n",
    "            \"mentee\": mentee\n",
    "        }\n",
    "        match_prob = predict_match_from_data(pair)\n",
    "\n",
    "        print(f\"멘토 {mentor['name']}의 매칭 확률: {match_prob:.4f}\")\n",
    "\n",
    "        if match_prob > best_match_prob:\n",
    "            best_match_prob = match_prob\n",
    "            best_mentor = mentor\n",
    "\n",
    "    return best_mentor, best_match_prob\n",
    "\n",
    "# 예시 멘티 데이터\n",
    "mentee = {\n",
    "    \"name\": \"윤하은\",\n",
    "    \"interests\": [\n",
    "        \"데이터 분석\",\n",
    "        \"Python 프로그래밍\"\n",
    "    ],\n",
    "    \"level\": 1,\n",
    "    \"bio\": \"데이터 분석과 Python 프로그래밍에 관심이 많은 취업 준비생입니다. 실무 경험을 쌓고 싶습니다.\"\n",
    "}\n",
    "\n",
    "# 여러 명의 멘토 리스트 (10명)\n",
    "mentors = [\n",
    "    {\n",
    "        \"name\": \"김수영\",\n",
    "        \"expertise\": [\n",
    "            \"데이터 시각화\",\n",
    "            \"Python\",\n",
    "            \"AI\"\n",
    "        ],\n",
    "        \"level\": 3,\n",
    "        \"bio\": \"데이터 시각화 및 AI 분야의 전문가입니다. Python을 통한 AI 모델 개발에 경험이 많습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"박민수\",\n",
    "        \"expertise\": [\n",
    "            \"프론트엔드 개발\",\n",
    "            \"React\",\n",
    "            \"JavaScript\"\n",
    "        ],\n",
    "        \"level\": 2,\n",
    "        \"bio\": \"프론트엔드 개발과 React에 대한 깊은 이해를 바탕으로 웹 개발 프로젝트를 성공적으로 이끌었습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"이하연\",\n",
    "        \"expertise\": [\n",
    "            \"데이터베이스\",\n",
    "            \"SQL\",\n",
    "            \"데이터 엔지니어링\"\n",
    "        ],\n",
    "        \"level\": 3,\n",
    "        \"bio\": \"SQL 및 데이터베이스 설계에 대한 풍부한 경험이 있으며, 데이터 엔지니어링 프로젝트를 다수 진행했습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"정윤호\",\n",
    "        \"expertise\": [\n",
    "            \"백엔드 개발\",\n",
    "            \"Node.js\",\n",
    "            \"AWS\"\n",
    "        ],\n",
    "        \"level\": 3,\n",
    "        \"bio\": \"백엔드 개발과 클라우드 서비스(AWS)에 대한 전문성을 보유하고 있으며, 서버 운영과 관련된 다양한 경험이 있습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"한지원\",\n",
    "        \"expertise\": [\n",
    "            \"기계 학습\",\n",
    "            \"TensorFlow\",\n",
    "            \"Keras\"\n",
    "        ],\n",
    "        \"level\": 2,\n",
    "        \"bio\": \"기계 학습 모델 개발과 관련된 프로젝트 경험이 풍부하며, TensorFlow와 Keras를 다루는 데 능숙합니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"서지호\",\n",
    "        \"expertise\": [\n",
    "            \"비즈니스 분석\",\n",
    "            \"프로젝트 관리\",\n",
    "            \"엑셀\"\n",
    "        ],\n",
    "        \"level\": 2,\n",
    "        \"bio\": \"엑셀을 활용한 비즈니스 분석과 프로젝트 관리 경험이 있으며, 기업의 생산성 향상을 위한 컨설팅을 제공하고 있습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"김나윤\",\n",
    "        \"expertise\": [\n",
    "            \"PPT 디자인\",\n",
    "            \"프레젠테이션\",\n",
    "            \"마케팅 전략\"\n",
    "        ],\n",
    "        \"level\": 3,\n",
    "        \"bio\": \"프레젠테이션과 PPT 디자인에 대한 경험이 풍부하며, 마케팅 전략을 효과적으로 전달하는 방법을 지도합니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"장민준\",\n",
    "        \"expertise\": [\n",
    "            \"AI 연구\",\n",
    "            \"자연어 처리\",\n",
    "            \"딥러닝\"\n",
    "        ],\n",
    "        \"level\": 3,\n",
    "        \"bio\": \"AI 연구와 자연어 처리 분야에서 다수의 프로젝트를 진행했으며, 딥러닝 모델 개발에 전문성을 가지고 있습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"최혜진\",\n",
    "        \"expertise\": [\n",
    "            \"UX/UI 디자인\",\n",
    "            \"사용자 경험\",\n",
    "            \"그래픽 디자인\"\n",
    "        ],\n",
    "        \"level\": 3,\n",
    "        \"bio\": \"UX/UI 디자인에 대한 깊은 이해와 다양한 사용자 경험 프로젝트를 진행했습니다. 그래픽 디자인에도 능숙합니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"이상혁\",\n",
    "        \"expertise\": [\n",
    "            \"모바일 앱 개발\",\n",
    "            \"Android\",\n",
    "            \"iOS\"\n",
    "        ],\n",
    "        \"level\": 2,\n",
    "        \"bio\": \"모바일 앱 개발(Android, iOS)에서의 경험이 많으며, 다양한 모바일 프로젝트를 성공적으로 완수했습니다.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 멘티와 가장 매칭 확률이 높은 멘토 찾기\n",
    "best_mentor, best_prob = find_best_match(mentee, mentors)\n",
    "print(f\"가장 매칭률이 높은 멘토: {best_mentor['name']} (매칭 확률: {best_prob:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 449,
     "status": "ok",
     "timestamp": 1729527000303,
     "user": {
      "displayName": "김영효",
      "userId": "02315814338804143440"
     },
     "user_tz": -540
    },
    "id": "m2cI_gIkrsT-",
    "outputId": "94efe573-bde1-4089-85c4-210411545794"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "멘토 송다은의 매칭 확률: 0.9855\n",
      "멘토 이하연의 매칭 확률: 0.2353\n",
      "멘토 정윤호의 매칭 확률: 0.6287\n",
      "멘토 한지원의 매칭 확률: 0.1220\n",
      "멘토 서지호의 매칭 확률: 0.7310\n",
      "멘토 김나윤의 매칭 확률: 0.1283\n",
      "멘토 장민준의 매칭 확률: 0.5103\n",
      "멘토 최혜진의 매칭 확률: 0.5307\n",
      "멘토 이상혁의 매칭 확률: 0.7501\n",
      "가장 매칭률이 높은 멘토: 송다은 (매칭 확률: 0.9855)\n"
     ]
    }
   ],
   "source": [
    "def predict_match_from_data(pair):\n",
    "    mentor_expertise = \", \".join(pair['mentor']['expertise'])\n",
    "    mentee_interests = \", \".join(pair['mentee']['interests'])\n",
    "    mentor_level = pair['mentor']['level']\n",
    "    mentee_level = pair['mentee']['level']\n",
    "    mentor_bio = pair['mentor']['bio']\n",
    "    mentee_bio = pair['mentee']['bio']\n",
    "\n",
    "    # 학습 시 사용한 형식대로 입력 텍스트를 구성합니다.\n",
    "    text = (\n",
    "        f\"멘토 전문 분야: {mentor_expertise}, 멘토 레벨: {mentor_level}, \"\n",
    "        f\"멘토 소개: {mentor_bio}, 멘티 관심사: {mentee_interests}, \"\n",
    "        f\"멘티 레벨: {mentee_level}, 멘티 소개: {mentee_bio}\"\n",
    "    )\n",
    "\n",
    "    # 토크나이징 및 인코딩\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    # 모델 예측\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask)\n",
    "        prob = torch.sigmoid(output)\n",
    "        return prob.item()\n",
    "\n",
    "def find_best_match(mentee, mentors):\n",
    "    best_match_prob = -1\n",
    "    best_mentor = None\n",
    "\n",
    "    # 각 멘토와 멘티의 매칭 확률을 계산하고 가장 높은 매칭 확률을 가진 멘토 선택\n",
    "    for mentor in mentors:\n",
    "        pair = {\n",
    "            \"mentor\": mentor,\n",
    "            \"mentee\": mentee\n",
    "        }\n",
    "        match_prob = predict_match_from_data(pair)\n",
    "\n",
    "        print(f\"멘토 {mentor['name']}의 매칭 확률: {match_prob:.4f}\")\n",
    "\n",
    "        if match_prob > best_match_prob:\n",
    "            best_match_prob = match_prob\n",
    "            best_mentor = mentor\n",
    "\n",
    "    return best_mentor, best_match_prob\n",
    "\n",
    "# 예시 멘티 데이터\n",
    "mentee = {\n",
    "    \"name\": \"한지우\",\n",
    "    \"interests\": [\n",
    "        \"생산성 향상\",\n",
    "        \"스피치 기술\",\n",
    "        \"엑셀 활용법\"\n",
    "    ],\n",
    "    \"level\": 1,\n",
    "    \"bio\": \"생산성 향상, 스피치 기술, 엑셀 활용법에 관심 있는 초급 멘티입니다. 많은 것을 배우고 싶습니다.\"\n",
    "}\n",
    "\n",
    "# 여러 명의 멘토 리스트 (10명)\n",
    "mentors = [\n",
    "    {\n",
    "        \"name\": \"송다은\",\n",
    "        \"expertise\": [\n",
    "            \"취업 및 이직\",\n",
    "            \"스피치 발표\",\n",
    "            \"생산성 툴\"\n",
    "        ],\n",
    "        \"level\": 2,\n",
    "        \"bio\": \"중급 수준의 취업 및 이직, 스피치 발표, 생산성 툴 전문가입니다. 직장 생활의 노하우를 전수해드리겠습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"이하연\",\n",
    "        \"expertise\": [\n",
    "            \"데이터베이스\",\n",
    "            \"SQL\",\n",
    "            \"데이터 엔지니어링\"\n",
    "        ],\n",
    "        \"level\": 5,\n",
    "        \"bio\": \"SQL 및 데이터베이스 설계에 대한 풍부한 경험이 있으며, 데이터 엔지니어링 프로젝트를 다수 진행했습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"정윤호\",\n",
    "        \"expertise\": [\n",
    "            \"백엔드 개발\",\n",
    "            \"Node.js\",\n",
    "            \"AWS\"\n",
    "        ],\n",
    "        \"level\": 4,\n",
    "        \"bio\": \"백엔드 개발과 클라우드 서비스(AWS)에 대한 전문성을 보유하고 있으며, 서버 운영과 관련된 다양한 경험이 있습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"한지원\",\n",
    "        \"expertise\": [\n",
    "            \"기계 학습\",\n",
    "            \"TensorFlow\",\n",
    "            \"Keras\"\n",
    "        ],\n",
    "        \"level\": 3,\n",
    "        \"bio\": \"기계 학습 모델 개발과 관련된 프로젝트 경험이 풍부하며, TensorFlow와 Keras를 다루는 데 능숙합니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"서지호\",\n",
    "        \"expertise\": [\n",
    "            \"비즈니스 분석\",\n",
    "            \"프로젝트 관리\",\n",
    "            \"엑셀\"\n",
    "        ],\n",
    "        \"level\": 2,\n",
    "        \"bio\": \"엑셀을 활용한 비즈니스 분석과 프로젝트 관리 경험이 있으며, 기업의 생산성 향상을 위한 컨설팅을 제공하고 있습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"김나윤\",\n",
    "        \"expertise\": [\n",
    "            \"PPT 디자인\",\n",
    "            \"프레젠테이션\",\n",
    "            \"마케팅 전략\"\n",
    "        ],\n",
    "        \"level\": 3,\n",
    "        \"bio\": \"프레젠테이션과 PPT 디자인에 대한 경험이 풍부하며, 마케팅 전략을 효과적으로 전달하는 방법을 지도합니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"장민준\",\n",
    "        \"expertise\": [\n",
    "            \"AI 연구\",\n",
    "            \"자연어 처리\",\n",
    "            \"딥러닝\"\n",
    "        ],\n",
    "        \"level\": 5,\n",
    "        \"bio\": \"AI 연구와 자연어 처리 분야에서 다수의 프로젝트를 진행했으며, 딥러닝 모델 개발에 전문성을 가지고 있습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"최혜진\",\n",
    "        \"expertise\": [\n",
    "            \"UX/UI 디자인\",\n",
    "            \"사용자 경험\",\n",
    "            \"그래픽 디자인\"\n",
    "        ],\n",
    "        \"level\": 3,\n",
    "        \"bio\": \"UX/UI 디자인에 대한 깊은 이해와 다양한 사용자 경험 프로젝트를 진행했습니다. 그래픽 디자인에도 능숙합니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"이상혁\",\n",
    "        \"expertise\": [\n",
    "            \"모바일 앱 개발\",\n",
    "            \"Android\",\n",
    "            \"iOS\"\n",
    "        ],\n",
    "        \"level\": 4,\n",
    "        \"bio\": \"모바일 앱 개발(Android, iOS)에서의 경험이 많으며, 다양한 모바일 프로젝트를 성공적으로 완수했습니다.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 멘티와 가장 매칭 확률이 높은 멘토 찾기\n",
    "best_mentor, best_prob = find_best_match(mentee, mentors)\n",
    "print(f\"가장 매칭률이 높은 멘토: {best_mentor['name']} (매칭 확률: {best_prob:.4f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fmBDEtkvB0A"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMgvaXB3WLAbe6juZD+TCyJ",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mentors_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
