{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멘티1명 멘토 10명 임시 정의\n",
    "mentee = {\n",
    "    \"name\": \"최지원\",\n",
    "    \"experience\": \"기초적인 Python 프로그래밍 경험이 있고, 머신러닝 입문 과정을 수강하였습니다. Kaggle에서 간단한 데이터 분석 프로젝트를 수행해보았습니다.\",\n",
    "    \"goals\": \"머신러닝 및 데이터 분석 역량을 키워, 향후 AI 연구자로 성장하고 싶습니다.\",\n",
    "    \"level\": \"초급\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "mentors = [\n",
    "    {\n",
    "        \"name\": \"김현우\",\n",
    "        \"mentoring_area\": [\"데이터 분석\", \"Python\", \"통계\"],\n",
    "        \"skills\": [\"Python\", \"Pandas\", \"Matplotlib\", \"Seaborn\", \"머신러닝\"],\n",
    "        \"desired_mentee_level\": \"초급\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"박지훈\",\n",
    "        \"mentoring_area\": [\"빅데이터\", \"데이터 엔지니어링\", \"SQL\"],\n",
    "        \"skills\": [\"SQL\", \"Spark\", \"Hadoop\", \"ETL\", \"데이터 파이프라인\"],\n",
    "        \"desired_mentee_level\": \"중급\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"이서연\",\n",
    "        \"mentoring_area\": [\"AI 모델링\", \"딥러닝\", \"컴퓨터 비전\"],\n",
    "        \"skills\": [\"TensorFlow\", \"Keras\", \"OpenCV\", \"PyTorch\"],\n",
    "        \"desired_mentee_level\": \"초급\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"정민수\",\n",
    "        \"mentoring_area\": [\"Java\", \"백엔드 개발\", \"API 설계\"],\n",
    "        \"skills\": [\"Java\", \"Spring Boot\", \"MySQL\", \"REST API\", \"Maven\"],\n",
    "        \"desired_mentee_level\": \"중급\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"최하영\",\n",
    "        \"mentoring_area\": [\"마케팅\", \"데이터 분석\", \"SNS 운영\"],\n",
    "        \"skills\": [\"Excel\", \"PowerPoint\", \"SEO\", \"SNS 광고\"],\n",
    "        \"desired_mentee_level\": \"초급\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"한재민\",\n",
    "        \"mentoring_area\": [\"데이터 시각화\", \"Python\", \"BI 도구\"],\n",
    "        \"skills\": [\"Tableau\", \"Power BI\", \"Python\", \"시각화 기법\"],\n",
    "        \"desired_mentee_level\": \"초급\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"이하늘\",\n",
    "        \"mentoring_area\": [\"법률 상담\", \"지적 재산권\"],\n",
    "        \"skills\": [\"지적재산권\", \"계약법\", \"민사소송법\"],\n",
    "        \"desired_mentee_level\": \"상급\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"류진영\",\n",
    "        \"mentoring_area\": [\"데이터 사이언스\", \"머신러닝\", \"AI\"],\n",
    "        \"skills\": [\"Scikit-learn\", \"Python\", \"R\", \"머신러닝 알고리즘\"],\n",
    "        \"desired_mentee_level\": \"초급\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"김나영\",\n",
    "        \"mentoring_area\": [\"프론트엔드 개발\", \"UI/UX 디자인\"],\n",
    "        \"skills\": [\"HTML\", \"CSS\", \"JavaScript\", \"React\", \"Figma\"],\n",
    "        \"desired_mentee_level\": \"중급\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"오승민\",\n",
    "        \"mentoring_area\": [\"모바일 앱 개발\", \"iOS 개발\"],\n",
    "        \"skills\": [\"Swift\", \"Objective-C\", \"Xcode\", \"UI 설계\"],\n",
    "        \"desired_mentee_level\": \"상급\"\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\smhrd1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords as nltk_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CustomElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\smhrd1\\AppData\\Local\\Temp\\ipykernel_2044\\3861715433.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('../models/KoELECTRA_base.pth', map_location=torch.device('cuda'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "멘토와의 적합도 점수:\n",
      "류진영: 0.9917\n",
      "박지훈: 0.9914\n",
      "정민수: 0.9875\n",
      "이서연: 0.9845\n",
      "김나영: 0.9757\n",
      "오승민: 0.9695\n",
      "한재민: 0.9676\n",
      "최하영: 0.9392\n",
      "이하늘: 0.9259\n",
      "김현우: 0.9001\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import ElectraPreTrainedModel, ElectraModel,AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 한국어 불용어 목록 정의 (실제 불용어 목록을 여기에 넣으세요)\n",
    "korean_stopwords = []  # 불용어 업슨ㄴ게 값이 더 잘나옴\n",
    "\n",
    "# 영어 불용어 목록 정의\n",
    "english_stopwords = nltk_stopwords.words('english')\n",
    "\n",
    "# Komoran 형태소 분석기 인스턴스 생성\n",
    "okt = Okt()\n",
    "\n",
    "# KoELECTRA 모델 및 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"monologg/kobert\", trust_remote_code=True)\n",
    "\n",
    "\n",
    "# 맞춤형 모델 클래스 정의\n",
    "class CustomElectraForSequenceClassification(ElectraPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.electra = ElectraModel(config)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        labels=None,\n",
    "        output_hidden_states=True,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.electra(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "        pooled_output = sequence_output[:, 0, :]  # [CLS] 토큰의 임베딩\n",
    "\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return output\n",
    "\n",
    "        return {'logits': logits, 'hidden_states': outputs.hidden_states}\n",
    "\n",
    "# 모델 로드\n",
    "model = CustomElectraForSequenceClassification.from_pretrained('monologg/koelectra-base-v3-discriminator', num_labels=1, ignore_mismatched_sizes=True)\n",
    "state_dict = torch.load('../models/KoELECTRA_base.pth', map_location=torch.device('cuda'))\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 전처리\n",
    "    text = re.sub(r'[^ㄱ-ㅎ가-힣a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.lower()\n",
    "    tokens = okt.pos(text)\n",
    "    \n",
    "    # 품사 선택에 맞게 수정\n",
    "    selected_pos = ['Noun', 'Verb', 'Adjective']\n",
    "    korean_words = [word for word, pos in tokens if pos in selected_pos and word not in korean_stopwords]\n",
    "    \n",
    "    # 영어 단어 추출\n",
    "    english_words = re.findall(r'\\b[a-z]+\\b', text)\n",
    "    english_words = [word for word in english_words if word not in english_stopwords]\n",
    "    \n",
    "    # 최종 단어 리스트 결합\n",
    "    words = korean_words + english_words\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            token_type_ids=inputs.get('token_type_ids', None),\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True\n",
    "        )\n",
    "    # [CLS] 토큰의 임베딩 추출\n",
    "    embedding = outputs['hidden_states'][-1][:, 0, :].detach().numpy()\n",
    "    return embedding.squeeze()\n",
    "\n",
    "\n",
    "\n",
    "# 가중치 설정\n",
    "goals_area_weight = 0.5         # 가장 높은 가중치\n",
    "experience_area_weight = 0.3    # 중간 가중치\n",
    "goals_skills_weight = 0.2       # 중간보다 낮은 가중치\n",
    "\n",
    "\n",
    "# 적합도 계산 함수\n",
    "def calculate_fit(mentee, mentors):\n",
    "    fit_scores = []\n",
    "\n",
    "    # 멘티의 goals와 experience 전처리 및 임베딩 생성\n",
    "    mentee_goals_processed = preprocess_text(mentee[\"goals\"])\n",
    "    mentee_goals_embedding = get_embedding(mentee_goals_processed)\n",
    "\n",
    "    mentee_experience_processed = preprocess_text(mentee[\"experience\"])\n",
    "    mentee_experience_embedding = get_embedding(mentee_experience_processed)\n",
    "\n",
    "    for mentor in mentors:\n",
    "        # 멘토의 mentoring_area와 skills 전처리 및 임베딩 생성\n",
    "        mentor_area_processed = preprocess_text(' '.join(mentor[\"mentoring_area\"]))\n",
    "        mentor_area_embedding = get_embedding(mentor_area_processed)\n",
    "\n",
    "        mentor_skills_processed = preprocess_text(' '.join(mentor[\"skills\"]))\n",
    "        mentor_skills_embedding = get_embedding(mentor_skills_processed)\n",
    "\n",
    "        # 유사도 계산\n",
    "        # 1. 멘티의 goals와 멘토의 mentoring_area 간의 유사도\n",
    "        goals_area_similarity = cosine_similarity(\n",
    "            [mentee_goals_embedding],\n",
    "            [mentor_area_embedding]\n",
    "        )[0][0]\n",
    "\n",
    "        # 2. 멘티의 experience와 멘토의 mentoring_area 간의 유사도\n",
    "        experience_area_similarity = cosine_similarity(\n",
    "            [mentee_experience_embedding],\n",
    "            [mentor_area_embedding]\n",
    "        )[0][0]\n",
    "\n",
    "        # 3. 멘티의 goals와 멘토의 skills 간의 유사도\n",
    "        goals_skills_similarity = cosine_similarity(\n",
    "            [mentee_goals_embedding],\n",
    "            [mentor_skills_embedding]\n",
    "        )[0][0]\n",
    "\n",
    "        # 가중치 적용하여 총 유사도 계산\n",
    "        total_similarity = (\n",
    "            goals_area_similarity * goals_area_weight +\n",
    "            experience_area_similarity * experience_area_weight +\n",
    "            goals_skills_similarity * goals_skills_weight\n",
    "        )\n",
    "\n",
    "        # 레벨 일치 여부에 따른 작은 가중치 적용\n",
    "        if mentee[\"level\"] == mentor[\"desired_mentee_level\"]:\n",
    "            level_bonus = 0.05  # 작은 보너스\n",
    "        else:\n",
    "            level_bonus = 0.05\n",
    "\n",
    "        # 총합 점수 계산\n",
    "        total_score = total_similarity + level_bonus\n",
    "        fit_scores.append((mentor[\"name\"], total_score))\n",
    "\n",
    "    return sorted(fit_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 멘토와의 적합도 계산 결과 출력\n",
    "fit_results = calculate_fit(mentee, mentors)\n",
    "print(\"멘토와의 적합도 점수:\")\n",
    "for mentor_name, score in fit_results:\n",
    "    print(f\"{mentor_name}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('김영훈', np.float32(0.980444)),\n",
       " ('이준혁', np.float32(0.97324747)),\n",
       " ('정예은', np.float32(0.9721156)),\n",
       " ('이현수', np.float32(0.9591866)),\n",
       " ('류시현', np.float32(0.92420393)),\n",
       " ('최성호', np.float32(0.92271453)),\n",
       " ('오지훈', np.float32(0.8229984)),\n",
       " ('박서현', np.float32(0.7999165)),\n",
       " ('한미정', np.float32(0.79189366)),\n",
       " ('김하윤', np.float32(0.60979855))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mentors_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
